
import matplotlib
from matplotlib import font_manager

!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv

fontpaths = ["C:/Users/kwon3/AppData/Local/Microsoft/Windows/Fonts/NanumGothicBold.ttf"]
font_files = font_manager.findSystemFonts(fontpaths=fontpaths)

for ff in font_files:
    font_manager.fontManager.addfont(ff)

matplotlib.rc('font', family="Malgun Gothic")
matplotlib.rcParams['axes.unicode_minus'] = False

# 데이터 경로
DATA_PATH = "C:/practice/finalproject/data/"
DATA_PATH

# 시드값
SEED = 42

# 데이터불러오기
import pandas as pd
import numpy as np

train_tr = pd.read_csv(f"{DATA_PATH}store_train_transactions.csv") # 학습용 구매기록 데이터
train_target = pd.read_csv(f"{DATA_PATH}store_train.csv") # 학습용 정답 데이터
test_tr = pd.read_csv(f"{DATA_PATH}store_test_transactions.csv") # 테스트용 구매기록 데이터
submit = pd.read_csv(f"{DATA_PATH}store_submission.csv") # 제출 양식 데이터

train_tr.shape , train_target.shape , test_tr.shape , submit.shape

submit = pd.read_csv(f"{DATA_PATH}store_submission.csv") # 제출 양식 데이터


#피처
train_ft = pd.read_csv(f"{DATA_PATH}train_common_1114.csv") # 학습 데이터(피처)
test_ft = pd.read_csv(f"{DATA_PATH}test_common_1114.csv") # 테스트 데이터(피처)

train_ft.shape , test_ft.shape


# 결측치 처리
mask = train_ft.isnull().sum() > 0
train_ft.isnull().sum()[mask]

mask = test_ft.isnull().sum() > 0
test_ft.isnull().sum()[mask]


train_ft = train_ft.iloc[:,1:]
test_ft = test_ft.iloc[:,1:]
train_ft.shape, test_ft.shape

cols = [ col for col in train_ft.columns if col.startswith("pivot_지점코드_") ]

train_ft["지점코드별_구매횟수_std"] = train_ft[cols].std(axis=1)
train_ft["지점코드별_구매횟수_skew"] = train_ft[cols].skew(axis=1)
train_ft["지점코드별_구매횟수_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["지점코드별_구매횟수_std"] = test_ft[cols].std(axis=1)
test_ft["지점코드별_구매횟수_skew"] = test_ft[cols].skew(axis=1)
test_ft["지점코드별_구매횟수_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape



cols = [ col for col in train_ft.columns if col.startswith("pivot_중분류_") ]  #중분류는 그대로쓰고, 다른건 차원축소하지많고,,, 

train_ft["중분류별_구매횟수_std"] = train_ft[cols].std(axis=1)
train_ft["중분류별_구매횟수_skew"] = train_ft[cols].skew(axis=1)
train_ft["중분류별_구매횟수_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["중분류별_구매횟수_std"] = test_ft[cols].std(axis=1)
test_ft["중분류별_구매횟수_skew"] = test_ft[cols].skew(axis=1)
test_ft["중분류별_구매횟수_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape

cols = [ col for col in train_ft.columns if col.startswith("pivot_대분류_") ]

train_ft["대분류별_구매횟수_std"] = train_ft[cols].std(axis=1)
train_ft["대분류별_구매횟수_skew"] = train_ft[cols].skew(axis=1)
train_ft["대분류별_구매횟수_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["대분류별_구매횟수_std"] = test_ft[cols].std(axis=1)
test_ft["대분류별_구매횟수_skew"] = test_ft[cols].skew(axis=1)
test_ft["대분류별_구매횟수_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape

cols = [ col for col in train_ft.columns if col.startswith("pivot_브랜드코드_") ] #써야하면 차원축소를 할것(버리던가,, 차원축소해서 옆으로붙이기) 

train_ft["브랜드코드별_구매횟수_std"] = train_ft[cols].std(axis=1)
train_ft["브랜드코드별_구매횟수_skew"] = train_ft[cols].skew(axis=1)
train_ft["브랜드코드별_구매횟수_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["브랜드코드별_구매횟수_std"] = test_ft[cols].std(axis=1)
test_ft["브랜드코드별_구매횟수_skew"] = test_ft[cols].skew(axis=1)
test_ft["브랜드코드별_구매횟수_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape


cols = [ col for col in train_ft.columns if col.endswith("요일_구매비율") ]

train_ft["요일별_구매비율_std"] = train_ft[cols].std(axis=1)
train_ft["요일별_구매비율_skew"] = train_ft[cols].skew(axis=1)
train_ft["요일별_구매비율_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["요일별_구매비율_std"] = test_ft[cols].std(axis=1)
test_ft["요일별_구매비율_skew"] = test_ft[cols].skew(axis=1)
test_ft["요일별_구매비율_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape


cols = [ col for col in train_ft.columns if col.endswith("월_구매비율") ]

train_ft["월별_구매비율_std"] = train_ft[cols].std(axis=1)
train_ft["월별_구매비율_skew"] = train_ft[cols].skew(axis=1)
train_ft["월별_구매비율_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["월별_구매비율_std"] = test_ft[cols].std(axis=1)
test_ft["월별_구매비율_skew"] = test_ft[cols].skew(axis=1)
test_ft["월별_구매비율_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape

cols = ["봄_구매비율","여름_구매비율","가을_구매비율","겨울_구매비율"]

train_ft["계절별_구매비율_std"] = train_ft[cols].std(axis=1)
train_ft["계절별_구매비율_skew"] = train_ft[cols].skew(axis=1)
train_ft["계절별_구매비율_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["계절별_구매비율_std"] = test_ft[cols].std(axis=1)
test_ft["계절별_구매비율_skew"] = test_ft[cols].skew(axis=1)
test_ft["계절별_구매비율_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape


cols = [ col for col in train_ft.columns if col.endswith("분기_구매비율") ]

train_ft["분기별_구매비율_std"] = train_ft[cols].std(axis=1)
train_ft["분기별_구매비율_skew"] = train_ft[cols].skew(axis=1)
train_ft["분기별_구매비율_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["분기별_구매비율_std"] = test_ft[cols].std(axis=1)
test_ft["분기별_구매비율_skew"] = test_ft[cols].skew(axis=1)
test_ft["분기별_구매비율_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape

cols = [ col for col in train_ft.columns if col.endswith("년_구매비율") ]

train_ft["년도별_구매비율_std"] = train_ft[cols].std(axis=1)
test_ft["년도별_구매비율_std"] = test_ft[cols].std(axis=1)

train_ft.shape, test_ft.shape


cols = ["봄_구매비율","여름_구매비율","가을_구매비율","겨울_구매비율"]

train_ft["계절별_구매비율_std"] = train_ft[cols].std(axis=1)
train_ft["계절별_구매비율_skew"] = train_ft[cols].skew(axis=1)
train_ft["계절별_구매비율_kurt"] = train_ft[cols].kurt(axis=1)

test_ft["계절별_구매비율_std"] = test_ft[cols].std(axis=1)
test_ft["계절별_구매비율_skew"] = test_ft[cols].skew(axis=1)
test_ft["계절별_구매비율_kurt"] = test_ft[cols].kurt(axis=1)

train_ft.shape, test_ft.shape

cols = [ col for col in train_ft.columns if col.startswith("18시") ]

train_ft["18시기준_구매비율_std"] = train_ft[cols].std(axis=1)

test_ft["18시기준_구매비율_std"] = test_ft[cols].std(axis=1)

train_ft.shape, test_ft.shape


# 주말에 중분류_아동용품_구매하는 비율(가족단위의 아이들용품 구매가 많지 않으까?)

train_ft["주말_중_아동용품_구매비율"] = train_ft["주말_구매비율"] * train_ft["주구매_중분류_아동용품"]

test_ft["주말_중_아동용품_구매비율"] = test_ft["주말_구매비율"] * test_ft["주구매_중분류_아동용품"]

train_ft.shape, test_ft.shape


# 주말에 중분류_아동용품_구매하는 비율(가족단위의 아이들용품 구매가 많지 않으까?)

train_ft["주말_대_아동용품_구매비율"] = train_ft["주말_구매비율"] * train_ft["주구매_대분류_아동용품"]

test_ft["주말_대_아동용품_구매비율"] = test_ft["주말_구매비율"] * test_ft["주구매_대분류_아동용품"]

train_ft.shape, test_ft.shape


# 18시이전이면서 주말에_중분류_아동용품_구매하는 비율
train_ft["18시이후_주말_중_아동용품_구매비율"] = train_ft["18시이후_구매비율"] * train_ft["주말_중_아동용품_구매비율"]
test_ft["18시이후_주말_중_아동용품_구매비율"] = test_ft["18시이후_구매비율"] * test_ft["주말_중_아동용품_구매비율"]

train_ft.shape, test_ft.shape



mask = train_ft.isnull().sum() > 0
train_ft.isnull().sum()[mask]

train_ft["첫구매날짜"] = pd.to_datetime(train_ft["첫구매날짜"])
train_ft["마지막구매날짜"] = pd.to_datetime(train_ft["마지막구매날짜"])
test_ft["첫구매날짜"] = pd.to_datetime(test_ft["첫구매날짜"])
test_ft["마지막구매날짜"] = pd.to_datetime(test_ft["마지막구매날짜"])

train_ft["첫구매년도"] = train_ft["첫구매날짜"].dt.year
train_ft["첫구매월"] = train_ft["첫구매날짜"].dt.month
train_ft["마지막구매년도"] = train_ft["마지막구매날짜"].dt.year
train_ft["마지막구매월"] = train_ft["마지막구매날짜"].dt.month

test_ft["첫구매년도"] = test_ft["첫구매날짜"].dt.year
test_ft["첫구매월"] = test_ft["첫구매날짜"].dt.month
test_ft["마지막구매년도"] = test_ft["마지막구매날짜"].dt.year
test_ft["마지막구매월"] = test_ft["마지막구매날짜"].dt.month

train_ft.shape, test_ft.shape

import category_encoders as ce
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

oh_enc = OneHotEncoder(handle_unknown="ignore")
oh_enc_cols = ["주구매지점","주구매_대분류", "주구매시간대"]
oh_enc_data = pd.concat([train_ft[oh_enc_cols], test_ft[oh_enc_cols]])
oh_enc.fit(oh_enc_data)

train_ft[oh_enc.get_feature_names_out()] = oh_enc.transform(train_ft[oh_enc_cols]).toarray()
test_ft[oh_enc.get_feature_names_out()] = oh_enc.transform(test_ft[oh_enc_cols]).toarray()

train_ft.shape, test_ft.shape

import category_encoders as ce
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

oh_enc = OneHotEncoder(handle_unknown="ignore")
oh_enc_cols = ["주구매지점", "주구매시간대"]
oh_enc_data = pd.concat([train_ft[oh_enc_cols], test_ft[oh_enc_cols]])
oh_enc.fit(oh_enc_data)

train_ft[oh_enc.get_feature_names_out()] = oh_enc.transform(train_ft[oh_enc_cols]).toarray()
test_ft[oh_enc.get_feature_names_out()] = oh_enc.transform(test_ft[oh_enc_cols]).toarray()

train_ft.shape, test_ft.shape

train_ft['선호브랜드코드'] = train_ft['선호브랜드코드'].astype('category')
test_ft['선호브랜드코드'] = test_ft['선호브랜드코드'].astype('category')

combined_brands = pd.concat([train_ft['선호브랜드코드'], test_ft['선호브랜드코드']])

enc = ce.CountEncoder()
train_ft["선호브랜드코드_cnt"] = enc.fit_transform(train_ft[['선호브랜드코드']])
test_ft["선호브랜드코드_cnt"] = enc.transform(test_ft[['선호브랜드코드']])

train_ft.shape, test_ft.shape


combined_categories = pd.concat([train_ft['주구매_중분류'], test_ft['주구매_중분류']])

enc = ce.count.CountEncoder()
train_ft["주구매_중분류_cnt"] = enc.fit_transform(train_ft[["주구매_중분류"]])
test_ft["주구매_중분류_cnt"] = enc.transform(test_ft[["주구매_중분류"]])

train_ft.shape, test_ft.shape


import pandas as pd

# 원핫인코딩 수행
train_ft = pd.get_dummies(train_ft, columns=['고객등급'], prefix='고객등급')

# 원핫인코딩된 열만 선택하여 True/False를 1/0으로 변환
for col in train_ft.filter(like='고객등급_').columns:
    train_ft[col] = train_ft[col].astype(int)

# 결과 확인
train_ft.head()

# 원핫인코딩 수행
test_ft = pd.get_dummies(test_ft, columns=['고객등급'], prefix='고객등급')

# 원핫인코딩된 열만 선택하여 True/False를 1/0으로 변환
for col in test_ft.filter(like='고객등급_').columns:
    test_ft[col] = test_ft[col].astype(int)

# 결과 확인
test_ft.head()

cols = train_ft.select_dtypes(["object", "datetime"]).columns.tolist()
cols

train_ft = train_ft.drop(columns=cols)
test_ft = test_ft.drop(columns=cols)
train_ft.shape, test_ft.shape

train_ft.select_dtypes("object").columns , test_ft.select_dtypes("object").columns

train_ft.select_dtypes("datetime").columns, test_ft.select_dtypes("datetime").columns


train_ft.isin([np.inf, -np.inf]).any().sum(), test_ft.isin([np.inf, -np.inf]).any().sum()

train_ft.isna().sum().sum(), test_ft.isna().sum().sum()

from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, Normalizer
scaler = Normalizer()

train_ft[train_ft.columns] = scaler.fit_transform(train_ft)
test_ft[test_ft.columns] = scaler.transform(test_ft)
train_ft.head()







# 앙상블

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import HistGradientBoostingClassifier



estimators = [
   # ("dt", DecisionTreeClassifier(random_state=42) ),
    #("hgb", HistGradientBoostingClassifier(max_iter=200, class_weight='balanced', random_state=42) ),
     ("hgb", HistGradientBoostingClassifier(max_iter=200, class_weight={0: 1, 1: 2}, random_state=42) ),
    #("knn", KNeighborsClassifier() ),
    ("lgb", LGBMClassifier() ),
    ("cbc", CatBoostClassifier() ),
    ("rfc", RandomForestClassifier(class_weight={0: 1 ,1: 2}, random_state=42)),
    #("lr", LogisticRegression(class_weight={0: 1, 1: 2}, random_state=42))

]



from sklearn.ensemble import VotingClassifier
parmas = {
    "estimators": estimators,
    "voting" : "soft",
    "n_jobs" : -1
}

model = VotingClassifier(**parmas)





from sklearn.model_selection import cross_val_score

# train_ft_tmp와 target을 numpy 배열로 변환
train_ft_X = train_ft_tmp.values  # DataFrame을 numpy 배열로 변환
target_y = target.values        # DataFrame을 numpy 배열로 변환
test_ft_X = test_ft_tmp.values



from imblearn.over_sampling import SMOTE
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score, classification_report
import pandas as pd
import numpy as np

# SMOTE 오버샘플링 적용 (훈련 데이터 전체에 적용)
smote = SMOTE(sampling_strategy=0.85, random_state=42)
train_ft_X_resampled, target_y_resampled = smote.fit_resample(train_ft_X, target_y)

# 클래스 분포 확인
print(f"Before SMOTE - target_y distribution:\n{pd.Series(target_y).value_counts()}")
print(f"After SMOTE - target_y_resampled distribution:\n{pd.Series(target_y_resampled).value_counts()}")

# 모델 생성
model = VotingClassifier(**parmas)

# 교차 검증 점수 계산 (훈련 데이터 전체로)
cv_scores = cross_val_score(model, train_ft_X_resampled, target_y_resampled, cv=5, scoring='f1_macro', n_jobs=-1)
print(f"Cross-Validation F1 Scores: {cv_scores}")
print(f"Mean CV F1 Score: {cv_scores.mean():.4f}\n")

# 모델 학습
model.fit(train_ft_X_resampled, target_y_resampled)

# 훈련 데이터 자체 평가 (검증 데이터 없이 전체 데이터 사용)
y_pred = model.predict(train_ft_X_resampled)

accuracy = accuracy_score(target_y_resampled, y_pred)
f1 = f1_score(target_y_resampled, y_pred, average='macro')

print(f"Train Accuracy: {accuracy:.4f}")
print(f"Train F1 Score: {f1:.4f}")
print("\nClassification Report:")
print(classification_report(target_y_resampled, y_pred))

# 테스트 데이터 예측
test_predictions = model.predict(test_ft_X)

test_probabilities = model.predict_proba(test_ft_X)
test_probabilities


# ID와 예측 확률을 결합
submission = pd.DataFrame({
    'ID': submit['ID'],  # 테스트 데이터의 ID
    'target': test_probabilities  
})

submission.to_csv('submit_이지은.csv', index=False)

print("제출 파일이 'submission.csv'로 저장되었습니다.")



# submit 제출파일
submit["target"] = test_predictions
submit
submit.to_csv(f"{DATA_PATH}submit_1114_.csv",index=False)



